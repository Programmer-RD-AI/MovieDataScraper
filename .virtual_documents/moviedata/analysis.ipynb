import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm


PATH = !pwd
PATH = PATH[-1]


PATH


# cast_data = pd.read_json(f"{PATH}/data/CastScraper/CastScraper.json").sample(frac=1)


faq_data = pd.read_json(f"{PATH}/data/FAQScraper/FAQScraper.json").sample(frac=1)


movie_data = pd.read_json(f"{PATH}/data/MovieDetailsScraper/MovieDetailsScraper.json").sample(frac=1)


movie_basic_data = pd.read_json(f"{PATH}/data/MoviesBasicDetailsScraper/MoviesBasicDetailsScraper.json").sample(frac=1)


photo_data = pd.read_json(f"{PATH}/data/PhotoScraper/PhotoScraper.json").sample(frac=1)


technical_specification_data = pd.read_json(f"{PATH}/data/TechnicalSpecificationsScraper/TechnicalSpecificationsScraper.json").sample(frac=1)


video_data = pd.read_json(f"{PATH}/data/VideoScraper/VideoScraper.json").sample(frac=1)


movieIds = np.unique(movie_basic_data['movieID'].astype(str))


faq_data.head()


movie_data.head()


movie_basic_data.head()


photo_data.head()


technical_specification_data.head()


video_data.head()


def type_faq_counter():
    faq_stats = {
        "movieID":[],
        "noOfFAQs":[]
    }
    for movieId in tqdm(movieIds):
        faqs_in_movie = faq_data[faq_data['movieID']==movieId]
        faq_stats["movieID"].append(movieId)
        faq_stats['noOfFAQs'].append(len(faqs_in_movie))
        for faq in faqs_in_movie["faqTitle"]:
            if not faq:
                continue
            name = faq.split(" ")[0].lower() + "Counter"
            if name not in faq_stats:
                faq_stats[name] = [0] * len(movieIds)
            faq_stats[name][np.where(movieIds == movieId)[0][0]] += 1
    return pd.DataFrame(faq_stats)


def prices():
    price_stats = {
        "movieID":[],
        "movieEarn":[],
        "movieBudget":[],
        "movieOther":[]
    }
    for movieId in tqdm(movieIds):
        earn = [0,1]
        budget = [0,1]
        other = [0,1]
        faqs_in_movie = faq_data[faq_data['movieID']==movieId]
        for content, title in zip(faqs_in_movie['faqContent'],faqs_in_movie['faqTitle']):
            if content and "$" in content:
                content = content.split(" ")
                if len(content) <= 1:
                    continue
                figure = content[-1][0].lower()
                price = float(content[0].replace(",","").replace("$", "")) * 1000 if figure == 'b' else float(content[0].replace(",","").replace("$", ""))
                if "earn" in title:
                    earn[0] += price
                    earn[1] += 1
                elif "budget" in title:
                    budget[0] += price
                    budget[1] += 1
                else:
                    other[0] += price
                    other[1] += 1
        price_stats["movieID"].append(movieId)
        price_stats["movieEarn"].append(earn[0]/earn[1])
        price_stats['movieBudget'].append(budget[0]/budget[1])
        price_stats['movieOther'].append(other[0]/other[1])
    return pd.DataFrame(price_stats)


def movie_statistics():
    movie_stats = movie_basic_data[["movieID","movieYear", "movieTime", "movieAvgRating", "movieRatingCount"]]
    movie_times = movie_stats['movieTime']
    movie_times_in_mins = []
    for movie_time in tqdm(movie_times):
        if not movie_time:
            movie_times_in_mins.append(None)
            continue
        split = movie_time.split(' ')
        if len(split) == 1:
            split.append("0m")
        hrs, mins = split
        tot = int(mins.strip().replace('m', ''))
        tot += int(hrs.strip().replace('h', '')) * 60 if hrs.strip().replace('h', '').isnumeric() else 0
        movie_times_in_mins.append(tot)
    movie_stats['movieTime'] = movie_times_in_mins
    ratings = movie_stats['movieRatingCount']
    new_ratings = []
    for rating in ratings:
        if not rating:
            new_ratings.append(None)
            continue
        sign = rating[-1].lower()
        if sign.isnumeric():
            new_ratings.append(float(rating))
        rating = rating.replace(rating[-1], "").strip()
        if sign == "k":
            new_ratings.append(float(rating) * 1000)
        elif sign == "m":
            new_ratings.append(float(rating) * 1000000)
    movie_stats['movieRatingCount'] = new_ratings
    return movie_stats


visualization_df = pd.merge(technical_specification_data[['movieID', 'specKey', 'specValue']], pd.merge(movie_statistics(), pd.merge(prices(),type_faq_counter(), on='movieID'), on="movieID"), on="movieID")


visualization_df


# sns.pairplot(visualization_df)


correlation_matrix = visualization_df.drop(['movieID', 'specKey', 'specValue'], axis=1).corr()
correlation_matrix.to_json("./data/heatmap.json")
# Set the style
sns.set(style="white")

# Create the heatmap
plt.figure(figsize=(12, 10))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".1f", linewidths=.5)

# Set title and adjust layout
plt.title('Correlation Heatmap of Features')
# plt.tight_layout()

# Show plot
plt.savefig("./data/heatmap.png")
plt.show()


sns.clustermap(correlation_matrix.dropna(axis=1, how='all').dropna(axis=0, how='all'), 
               annot=True,  # Show the correlation values in each cell
               cmap='coolwarm',  # Color map
               figsize=(12, 10))  # Size of the figure


numerical_attributes = ['movieYear', 'movieTime', 'movieAvgRating', 'movieRatingCount', 'movieEarn', 'movieBudget']

# Generating summary statistics
summary_stats = visualization_df[numerical_attributes].describe()

# Adding median as an additional row
median_row = visualization_df[numerical_attributes].median().to_frame().T
median_row.index = ['50%']
summary_stats = pd.concat([summary_stats, median_row])

# Extract summary statistics from the DataFrame
summary_stats_values = summary_stats.iloc[0]
summary_stats_name = summary_stats.iloc[0].name

# Bar plot for summary statistics
plt.figure(figsize=(10, 6))
sns.barplot(x=summary_stats.columns, y=summary_stats_values)
plt.title('Summary Statistics for Numerical Attributes')
plt.ylabel(summary_stats_name)
plt.show()


# Count plot for specKey
plt.figure(figsize=(12, 8))
sns.countplot(data=visualization_df, x='specKey', palette='viridis')
plt.title('Frequency of Technical Specifications')
plt.xlabel('Specification Key')
plt.ylabel('Frequency')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

# Count plot for specValue
plt.figure(figsize=(12, 8))
sns.countplot(data=visualization_df, y='specValue', palette='magma', order=visualization_df['specValue'].value_counts().index[:20])
plt.title('Top 20 Most Common Specification Values')
plt.xlabel('Frequency')
plt.ylabel('Specification Value')
plt.tight_layout()
plt.show()


plt.figure(figsize=(12, 8))
sns.violinplot(data=visualization_df, x='specKey', y='movieYear', palette='Pastel1')
plt.title('Distribution of Numerical Attribute by Specification Key')
plt.xlabel('Specification Key')
plt.ylabel('Numerical Attribute')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()


plt.figure(figsize=(12, 8))
sns.violinplot(data=visualization_df, x='specKey', y='movieEarn', palette='Pastel1')
plt.title('Distribution of Numerical Attribute by Specification Key')
plt.xlabel('Specification Key')
plt.ylabel('Numerical Attribute')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()


plt.figure(figsize=(12, 8))
sns.violinplot(data=visualization_df, x='specKey', y='movieAvgRating', palette='Pastel1')
plt.title('Distribution of Numerical Attribute by Specification Key')
plt.xlabel('Specification Key')
plt.ylabel('Numerical Attribute')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()


plt.figure(figsize=(12, 8))
sns.violinplot(data=visualization_df, x='specKey', y='movieTime', palette='Pastel1')
plt.title('Distribution of Numerical Attribute by Specification Key')
plt.xlabel('Specification Key')
plt.ylabel('Numerical Attribute')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()


descriptions = movie_data['movieDescription']
story_lines = movie_data['storyLine']


from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from wordcloud import WordCloud


# Tokenize and preprocess the text data
stop_words = set(stopwords.words('english'))

word_tokens = []
for description in descriptions:
    words = word_tokenize(description.lower())  # Convert to lowercase
    words = [word for word in words if word.isalnum()]  # Remove punctuation
    words = [word for word in words if word not in stop_words]  # Remove stopwords
    word_tokens.extend(words)

# Join the words into a single string
text = ' '.join(word_tokens)

# Generate the word cloud
wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)

# Plot the word cloud
plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.show()


# Tokenize and preprocess the text data
stop_words = set(stopwords.words('english'))

word_tokens = []
for story_line in story_lines.dropna():
    words = word_tokenize(story_line.lower())  # Convert to lowercase
    words = [word for word in words if word.isalnum()]  # Remove punctuation
    words = [word for word in words if word not in stop_words]  # Remove stopwords
    word_tokens.extend(words)

# Join the words into a single string
text = ' '.join(word_tokens)

# Generate the word cloud
wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)

# Plot the word cloud
plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.show()


# sns.pairplot(visualization_df, diag_kind="kde")


# Subset the DataFrame to include only numerical attributes
numerical_attributes = ['movieYear', 'movieTime', 'movieAvgRating', 'movieRatingCount', 'movieEarn', 'movieBudget']
numerical_df = visualization_df[numerical_attributes]

# Drop any rows with missing values
numerical_df.dropna(inplace=True)

# Create a pair plot
sns.pairplot(numerical_df)
plt.show()


visualization_df.isna().sum()






